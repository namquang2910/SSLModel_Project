{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bdf74aa-e5ad-4225-b4b0-a733e28d17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pywt\n",
    "import os\n",
    "import csv \n",
    "from tqdm import tqdm\n",
    "import neurokit2 as nk\n",
    "\n",
    "from ArrhythmiaModel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4352ea-9362-4248-8724-b7ed365272ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data):\n",
    "    band_passed_ecg =  nk.signal_filter(data, sampling_rate=360, lowcut=0.1, highcut=100, method='butterworth_zi', order = 2)\n",
    "    emg = moving_average(band_passed_ecg, window_size=10)\n",
    "    # Step 4: Downsample the filtered ECG signal \n",
    "    downsampled_ecg = nk.signal_resample(emg, sampling_rate=360, desired_sampling_rate=100)\n",
    "    return downsampled_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d5d2b0-2458-4747-ac0e-71a9925b4686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                               | 0/11 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preprocessing_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m\n\u001b[1;32m      5\u001b[0m mask_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mload_multiple_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m test_data \u001b[38;5;241m=\u001b[39m load_multiple_records([(\u001b[38;5;241m233\u001b[39m,\u001b[38;5;241m234\u001b[39m)], seq_len, stride)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m]: \n",
      "File \u001b[0;32m~/NamQuang/SSLModel/ArrhythmiaModel.py:94\u001b[0m, in \u001b[0;36mload_multiple_records\u001b[0;34m(record_ranges, seq_len, stride_len)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start, end \u001b[38;5;129;01min\u001b[39;00m tqdm(record_ranges):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m record_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 94\u001b[0m         record_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m         all_data\u001b[38;5;241m.\u001b[39mextend(record_data)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Save to pkl\u001b[39;00m\n",
      "File \u001b[0;32m~/NamQuang/SSLModel/ArrhythmiaModel.py:73\u001b[0m, in \u001b[0;36mload_record\u001b[0;34m(record_id, seq_len, stride)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#Extract each channel\u001b[39;00m\n\u001b[1;32m     72\u001b[0m signal_data \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mp_signal\n\u001b[0;32m---> 73\u001b[0m ch1 \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing_data\u001b[49m(signal_data[:, \u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     74\u001b[0m ch2 \u001b[38;5;241m=\u001b[39m preprocessing_data(signal_data[:, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m#Scale the signal\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessing_data' is not defined"
     ]
    }
   ],
   "source": [
    "record_ranges = [(100,109),(111, 119),(121,124),(200,203),(205,205),(207,210),(212,215),(217,217),(219,223),(228,228),(230,232)]\n",
    "print(\"Working with data\")\n",
    "seq_len = 500\n",
    "stride = 500\n",
    "mask_length = 30\n",
    "data = np.array(load_multiple_records(record_ranges, seq_len, stride))\n",
    "test_data = load_multiple_records([(233,234)], seq_len, stride)\n",
    "\n",
    "for num in [3]: \n",
    "    print(\"=\"*20)\n",
    "    print(f\"Training the model with {num} R peaks\")\n",
    "    print(\"=\"*20)\n",
    "    \n",
    "    print(\"Preparing the data\")\n",
    "    train_loader, val_loader = prepare_data(data,num_rpeaks = num, seq_len=seq_len, mask_len = mask_length)\n",
    "    test_dataset = ECGDataset(test_data, seq_len, num_peaks_to_mask = num)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    print(\"Training the model\")\n",
    "    criterion = nn.MSELoss()\n",
    "    mae_model = MAE1D_Mask()\n",
    "    optimizer = optim.Adam(mae_model.parameters(), lr=0.001)    \n",
    "\n",
    "    model_trainer = Trainer(model = mae_model, \n",
    "                            criterion = criterion, optimizer = optimizer,  \n",
    "                            seq_len=seq_len, masking_length = mask_length, num_rpeak=num, \n",
    "                            scale = 'Minmax_05',\n",
    "                            test_case = False)\n",
    "    model_trainer.run(train_loader, val_loader, test_loader, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68242e0b-8040-497e-b391-0bb5a109aa11",
   "metadata": {},
   "source": [
    "# Fine- truning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35967a42-d2c9-4143-b234-4093910ab208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from wesad_processing import *\n",
    "WIN_SIZE = 10\n",
    "def load_wesad_dataset(root_dir, test_subject):\n",
    "    folder_ls = os.listdir(root_dir)\n",
    "    for i in folder_ls:\n",
    "        if i == \".ipynb_checkpoints\" or i == '.DS_Store':\n",
    "            folder_ls.remove(i)\n",
    "    \n",
    "    valid_ls = test_subject\n",
    "    # Create the train list by excluding test_ls\n",
    "    train_ls = [subject for subject in folder_ls if subject not in valid_ls]\n",
    "    print(\"==========Loading Training set============\")\n",
    "    X_train, y_train = load_process_extract_ls(root_dir, train_ls,700, WIN_SIZE,WIN_SIZE,True)\n",
    "    print(\"==========Loading Testing set============\")\n",
    "    X_test, y_test = load_process_extract_ls(root_dir,valid_ls,700, WIN_SIZE, WIN_SIZE,False)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "class ECGClassificationDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X  # shape: [N, L]\n",
    "        self.Y = Y  # shape: [N]\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.X[idx].flatten()\n",
    "        return torch.tensor(seq, dtype=torch.float32).unsqueeze(0), torch.tensor(self.Y[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4798e0-bee6-4a7f-a344-a08a5f2dcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownstreamClassifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes=2):\n",
    "        super(DownstreamClassifier, self).__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # Freeze encoder parameters\n",
    "        for param in self.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Classifier head after GAP\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(negative_slope = 0.01),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # If no mask given, create a zero-mask (no masking)\n",
    "        if mask is None:\n",
    "            mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "\n",
    "        x = x.squeeze(1)         # (B, L)\n",
    "        mask = mask.squeeze(1)   # (B, L)\n",
    "\n",
    "        # Pass through encoder\n",
    "        z = self.encoder(x, mask, mask)  # -> (B, C, L)\n",
    "\n",
    "        # Global Average Pooling over sequence dimension\n",
    "        z = F.adaptive_avg_pool1d(z, 1)  # -> (B, C, 1)\n",
    "        z = z.squeeze(-1)                # -> (B, C)\n",
    "\n",
    "        logits = self.classifier(z)      # -> (B, num_classes)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2e603be-961c-4d0f-a70f-7ba96f5ac813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {\"params\": model.encoder.parameters(), \"lr\": 1e-8},     # smaller LR for encoder\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 1e-3}   # larger LR for classifier\n",
    "    ], weight_decay=1e-4)\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    \n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in dataloader:\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            outputs = model(x_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_val_preds.extend(preds.cpu().numpy())\n",
    "            all_val_labels.extend(y_val.cpu().numpy())\n",
    "    \n",
    "    prec_temp = precision_score(all_val_labels, all_val_preds)\n",
    "    rec_temp = recall_score(all_val_labels, all_val_preds)\n",
    "    f1_temp = f1_score(all_val_labels, all_val_preds,average='macro')\n",
    "    acc_temp = accuracy_score(all_val_labels, all_val_preds)\n",
    "    \n",
    "    return prec_temp, rec_temp, f1_temp, acc_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3b4ea5-ab7e-4bd1-bf18-0cee92f2dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_downstream_classifier(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    num_epochs=60,\n",
    "    device = 'cuda'\n",
    "):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam([\n",
    "        {\"params\": model.encoder.parameters(), \"lr\": 1e-8},     # smaller LR for encoder\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": 1e-3}   # larger LR for classifier\n",
    "    ], weight_decay=1e-4)\n",
    "    model.to(device)\n",
    "    val_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_train_preds = []\n",
    "        all_train_labels = []\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_train_preds.extend(preds.cpu().numpy())\n",
    "            all_train_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        train_accuracy = accuracy_score(all_train_labels, all_train_preds)\n",
    "        train_f1_macro = f1_score(all_train_labels, all_train_preds, average='macro')\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_val_preds = []\n",
    "        all_val_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for x_val, y_val in val_loader:\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                outputs = model(x_val)\n",
    "                loss = criterion(outputs, y_val)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_val_preds.extend(preds.cpu().numpy())\n",
    "                all_val_labels.extend(y_val.cpu().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_val_labels, all_val_preds)\n",
    "        val_f1_macro = f1_score(all_val_labels, all_val_preds, average='macro')\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch}: \"\n",
    "              f\"Train Loss = {total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Train Acc = {train_accuracy:.4f}, \"\n",
    "              f\"Train F1 = {train_f1_macro:.4f} | \"\n",
    "              f\"Val Loss = {avg_val_loss:.4f}, \"\n",
    "              f\"Val Acc = {val_accuracy:.4f}, \"\n",
    "              f\"Val F1 = {val_f1_macro:.4f}\")\n",
    "        \n",
    "    prec, rec, f1, acc = evaluate(model, test_loader, criterion, device)\n",
    "    return prec, rec, f1, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2978324-af13-4eef-9da2-7207771d8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loso_training(root_dir, sample_rate, test_size, filename, load_file):\n",
    "    prec, rec, acc, f1 = [], [], [], []\n",
    "    folder_ls = [f for f in os.listdir(root_dir) if f not in (\".ipynb_checkpoints\", \".DS_Store\")]\n",
    "    start_index = np.arange(0, len(folder_ls) - test_size + 1, test_size)\n",
    "\n",
    "    # Load pretrained model once\n",
    "    auto_model = MAE1D_Mask()\n",
    "    auto_model.load_state_dict(torch.load(\n",
    "        'runs/seq500_rpeak3_0213_03092025/model_500_3_0213_03092025.pth', \n",
    "        weights_only=True\n",
    "    ))\n",
    "    encoder = auto_model.encoder\n",
    "\n",
    "    for start in start_index:\n",
    "        subj = folder_ls[start:start + test_size]\n",
    "        print(f\"***** Loop {start}: {subj} *****\")\n",
    "\n",
    "        # Load dataset\n",
    "        X_train, X_test, y_train, y_test = load_wesad_dataset(root_dir, subj)\n",
    "        train_dataset = ECGClassificationDataset(X_train, y_train)\n",
    "        test_dataset = ECGClassificationDataset(X_test, y_test)\n",
    "\n",
    "        # Split train/val\n",
    "        train_size = int(0.8 * len(train_dataset))\n",
    "        val_size = len(train_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "        loaders = {\n",
    "            'train': DataLoader(train_dataset, batch_size=128, shuffle=True),\n",
    "            'val': DataLoader(val_dataset, batch_size=128, shuffle=False),\n",
    "            'test': DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "        }\n",
    "\n",
    "        # Train and evaluate downstream classifier\n",
    "        model = DownstreamClassifier(encoder)\n",
    "        prec_, rec_, f1_, acc_ = train_evaluate_downstream_classifier(\n",
    "            model, loaders['train'], loaders['val'], loaders['test'], num_epochs=100, device='cuda'\n",
    "        )\n",
    "        prec.append(prec_); rec.append(rec_); f1.append(f1_); acc.append(acc_)\n",
    "        print([start, acc_, f1_, rec_, prec_])\n",
    "\n",
    "        # Save iteration results\n",
    "        with open(filename, 'a', newline='') as f:\n",
    "            csv.writer(f).writerow([start, acc_, f1_, rec_, prec_, subj])\n",
    "\n",
    "    # Save mean results\n",
    "    with open(filename, 'a', newline='') as f:\n",
    "        csv.writer(f).writerow([np.mean(acc), np.mean(f1), np.mean(prec), np.mean(rec)])\n",
    "\n",
    "    print(f\"Accuracy: {np.mean(acc)}, F1: {np.mean(f1)}, Precision: {np.mean(prec)}, Recall: {np.mean(rec)}\")\n",
    "    return acc, f1, rec, prec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edcb4065-67e5-47b2-bf1e-3a4193d6c223",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Loop 0: ['S16'] *****\n",
      "==========Loading Training set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S9/S9.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S13/S13.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S8/S8.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S4/S4.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S11/S11.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S15/S15.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S3/S3.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S2/S2.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S6/S6.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S7/S7.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S14/S14.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S10/S10.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S5/S5.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S17/S17.pkl\n",
      "(4123, 1000, 1)\n",
      "==========Loading Testing set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S16/S16.pkl\n",
      "Epoch 0: Train Loss = 0.5160, Train Acc = 0.7605, Train F1 = 0.4790 | Val Loss = 0.4224, Val Acc = 0.8145, Val F1 = 0.6003\n",
      "Epoch 1: Train Loss = 0.3743, Train Acc = 0.8487, Train F1 = 0.6950 | Val Loss = 0.3221, Val Acc = 0.8848, Val F1 = 0.8029\n",
      "Epoch 2: Train Loss = 0.3007, Train Acc = 0.8842, Train F1 = 0.7972 | Val Loss = 0.2628, Val Acc = 0.8982, Val F1 = 0.8252\n",
      "Epoch 3: Train Loss = 0.2483, Train Acc = 0.9060, Train F1 = 0.8451 | Val Loss = 0.2231, Val Acc = 0.9176, Val F1 = 0.8706\n",
      "Epoch 4: Train Loss = 0.2157, Train Acc = 0.9190, Train F1 = 0.8683 | Val Loss = 0.1999, Val Acc = 0.9248, Val F1 = 0.8857\n",
      "Epoch 5: Train Loss = 0.1938, Train Acc = 0.9260, Train F1 = 0.8838 | Val Loss = 0.1872, Val Acc = 0.9236, Val F1 = 0.8758\n",
      "Epoch 6: Train Loss = 0.1836, Train Acc = 0.9266, Train F1 = 0.8850 | Val Loss = 0.1724, Val Acc = 0.9285, Val F1 = 0.8870\n",
      "Epoch 7: Train Loss = 0.1679, Train Acc = 0.9345, Train F1 = 0.8970 | Val Loss = 0.1607, Val Acc = 0.9382, Val F1 = 0.9069\n",
      "Epoch 8: Train Loss = 0.1588, Train Acc = 0.9378, Train F1 = 0.9030 | Val Loss = 0.1517, Val Acc = 0.9406, Val F1 = 0.9090\n",
      "Epoch 9: Train Loss = 0.1531, Train Acc = 0.9427, Train F1 = 0.9114 | Val Loss = 0.1500, Val Acc = 0.9358, Val F1 = 0.8989\n",
      "Epoch 10: Train Loss = 0.1429, Train Acc = 0.9478, Train F1 = 0.9192 | Val Loss = 0.1546, Val Acc = 0.9418, Val F1 = 0.9161\n",
      "Epoch 11: Train Loss = 0.1437, Train Acc = 0.9418, Train F1 = 0.9109 | Val Loss = 0.1378, Val Acc = 0.9406, Val F1 = 0.9078\n",
      "Epoch 12: Train Loss = 0.1356, Train Acc = 0.9482, Train F1 = 0.9207 | Val Loss = 0.1366, Val Acc = 0.9455, Val F1 = 0.9196\n",
      "Epoch 13: Train Loss = 0.1328, Train Acc = 0.9527, Train F1 = 0.9279 | Val Loss = 0.1299, Val Acc = 0.9527, Val F1 = 0.9297\n",
      "Epoch 14: Train Loss = 0.1300, Train Acc = 0.9503, Train F1 = 0.9238 | Val Loss = 0.1306, Val Acc = 0.9564, Val F1 = 0.9370\n",
      "Epoch 15: Train Loss = 0.1250, Train Acc = 0.9563, Train F1 = 0.9338 | Val Loss = 0.1231, Val Acc = 0.9515, Val F1 = 0.9281\n",
      "Epoch 16: Train Loss = 0.1199, Train Acc = 0.9551, Train F1 = 0.9319 | Val Loss = 0.1233, Val Acc = 0.9564, Val F1 = 0.9360\n",
      "Epoch 17: Train Loss = 0.1174, Train Acc = 0.9563, Train F1 = 0.9341 | Val Loss = 0.1259, Val Acc = 0.9576, Val F1 = 0.9394\n",
      "Epoch 18: Train Loss = 0.1145, Train Acc = 0.9609, Train F1 = 0.9408 | Val Loss = 0.1145, Val Acc = 0.9600, Val F1 = 0.9424\n",
      "Epoch 19: Train Loss = 0.1123, Train Acc = 0.9572, Train F1 = 0.9358 | Val Loss = 0.1128, Val Acc = 0.9539, Val F1 = 0.9311\n",
      "Epoch 20: Train Loss = 0.1123, Train Acc = 0.9579, Train F1 = 0.9366 | Val Loss = 0.1128, Val Acc = 0.9588, Val F1 = 0.9401\n",
      "Epoch 21: Train Loss = 0.1112, Train Acc = 0.9594, Train F1 = 0.9389 | Val Loss = 0.1082, Val Acc = 0.9552, Val F1 = 0.9336\n",
      "Epoch 22: Train Loss = 0.1073, Train Acc = 0.9594, Train F1 = 0.9387 | Val Loss = 0.1078, Val Acc = 0.9624, Val F1 = 0.9459\n",
      "Epoch 23: Train Loss = 0.1047, Train Acc = 0.9579, Train F1 = 0.9369 | Val Loss = 0.1097, Val Acc = 0.9527, Val F1 = 0.9279\n",
      "Epoch 24: Train Loss = 0.1013, Train Acc = 0.9621, Train F1 = 0.9428 | Val Loss = 0.1105, Val Acc = 0.9576, Val F1 = 0.9387\n",
      "Epoch 25: Train Loss = 0.1078, Train Acc = 0.9588, Train F1 = 0.9383 | Val Loss = 0.1085, Val Acc = 0.9600, Val F1 = 0.9431\n",
      "Epoch 26: Train Loss = 0.0994, Train Acc = 0.9633, Train F1 = 0.9451 | Val Loss = 0.1008, Val Acc = 0.9624, Val F1 = 0.9465\n",
      "Epoch 27: Train Loss = 0.0973, Train Acc = 0.9648, Train F1 = 0.9472 | Val Loss = 0.0950, Val Acc = 0.9685, Val F1 = 0.9547\n",
      "Epoch 28: Train Loss = 0.0930, Train Acc = 0.9660, Train F1 = 0.9494 | Val Loss = 0.0978, Val Acc = 0.9588, Val F1 = 0.9398\n",
      "Epoch 29: Train Loss = 0.0931, Train Acc = 0.9639, Train F1 = 0.9459 | Val Loss = 0.0932, Val Acc = 0.9661, Val F1 = 0.9508\n",
      "Epoch 30: Train Loss = 0.0898, Train Acc = 0.9666, Train F1 = 0.9504 | Val Loss = 0.0927, Val Acc = 0.9673, Val F1 = 0.9521\n",
      "Epoch 31: Train Loss = 0.0895, Train Acc = 0.9660, Train F1 = 0.9495 | Val Loss = 0.0958, Val Acc = 0.9612, Val F1 = 0.9420\n",
      "Epoch 32: Train Loss = 0.0877, Train Acc = 0.9660, Train F1 = 0.9495 | Val Loss = 0.0939, Val Acc = 0.9612, Val F1 = 0.9432\n",
      "Epoch 33: Train Loss = 0.0862, Train Acc = 0.9645, Train F1 = 0.9468 | Val Loss = 0.0927, Val Acc = 0.9685, Val F1 = 0.9549\n",
      "Epoch 34: Train Loss = 0.0862, Train Acc = 0.9682, Train F1 = 0.9525 | Val Loss = 0.0965, Val Acc = 0.9709, Val F1 = 0.9585\n",
      "Epoch 35: Train Loss = 0.0847, Train Acc = 0.9663, Train F1 = 0.9497 | Val Loss = 0.0846, Val Acc = 0.9709, Val F1 = 0.9584\n",
      "Epoch 36: Train Loss = 0.0845, Train Acc = 0.9660, Train F1 = 0.9490 | Val Loss = 0.0818, Val Acc = 0.9721, Val F1 = 0.9597\n",
      "Epoch 37: Train Loss = 0.0814, Train Acc = 0.9691, Train F1 = 0.9539 | Val Loss = 0.0975, Val Acc = 0.9721, Val F1 = 0.9610\n",
      "Epoch 38: Train Loss = 0.0825, Train Acc = 0.9700, Train F1 = 0.9552 | Val Loss = 0.0830, Val Acc = 0.9745, Val F1 = 0.9629\n",
      "Epoch 39: Train Loss = 0.0771, Train Acc = 0.9685, Train F1 = 0.9529 | Val Loss = 0.0845, Val Acc = 0.9673, Val F1 = 0.9527\n",
      "Epoch 40: Train Loss = 0.0761, Train Acc = 0.9712, Train F1 = 0.9570 | Val Loss = 0.0796, Val Acc = 0.9733, Val F1 = 0.9614\n",
      "Epoch 41: Train Loss = 0.0753, Train Acc = 0.9697, Train F1 = 0.9551 | Val Loss = 0.0818, Val Acc = 0.9697, Val F1 = 0.9550\n",
      "Epoch 42: Train Loss = 0.0754, Train Acc = 0.9706, Train F1 = 0.9561 | Val Loss = 0.0859, Val Acc = 0.9685, Val F1 = 0.9552\n",
      "Epoch 43: Train Loss = 0.0783, Train Acc = 0.9697, Train F1 = 0.9552 | Val Loss = 0.0807, Val Acc = 0.9709, Val F1 = 0.9579\n",
      "Epoch 44: Train Loss = 0.0761, Train Acc = 0.9673, Train F1 = 0.9512 | Val Loss = 0.0825, Val Acc = 0.9685, Val F1 = 0.9547\n",
      "Epoch 45: Train Loss = 0.0768, Train Acc = 0.9712, Train F1 = 0.9574 | Val Loss = 0.0785, Val Acc = 0.9782, Val F1 = 0.9682\n",
      "Epoch 46: Train Loss = 0.0718, Train Acc = 0.9739, Train F1 = 0.9613 | Val Loss = 0.0752, Val Acc = 0.9733, Val F1 = 0.9615\n",
      "Epoch 47: Train Loss = 0.0727, Train Acc = 0.9730, Train F1 = 0.9598 | Val Loss = 0.0908, Val Acc = 0.9661, Val F1 = 0.9523\n",
      "Epoch 48: Train Loss = 0.0706, Train Acc = 0.9721, Train F1 = 0.9586 | Val Loss = 0.0732, Val Acc = 0.9721, Val F1 = 0.9599\n",
      "Epoch 49: Train Loss = 0.0685, Train Acc = 0.9736, Train F1 = 0.9608 | Val Loss = 0.0743, Val Acc = 0.9770, Val F1 = 0.9662\n",
      "Epoch 50: Train Loss = 0.0668, Train Acc = 0.9742, Train F1 = 0.9617 | Val Loss = 0.0731, Val Acc = 0.9733, Val F1 = 0.9614\n",
      "Epoch 51: Train Loss = 0.0658, Train Acc = 0.9724, Train F1 = 0.9589 | Val Loss = 0.0805, Val Acc = 0.9685, Val F1 = 0.9545\n",
      "Epoch 52: Train Loss = 0.0663, Train Acc = 0.9757, Train F1 = 0.9640 | Val Loss = 0.0786, Val Acc = 0.9685, Val F1 = 0.9547\n",
      "Epoch 53: Train Loss = 0.0661, Train Acc = 0.9745, Train F1 = 0.9623 | Val Loss = 0.0669, Val Acc = 0.9770, Val F1 = 0.9664\n",
      "Epoch 54: Train Loss = 0.0641, Train Acc = 0.9751, Train F1 = 0.9631 | Val Loss = 0.0665, Val Acc = 0.9745, Val F1 = 0.9632\n",
      "Epoch 55: Train Loss = 0.0607, Train Acc = 0.9754, Train F1 = 0.9635 | Val Loss = 0.0766, Val Acc = 0.9709, Val F1 = 0.9567\n",
      "Epoch 56: Train Loss = 0.0630, Train Acc = 0.9785, Train F1 = 0.9682 | Val Loss = 0.0665, Val Acc = 0.9745, Val F1 = 0.9632\n",
      "Epoch 57: Train Loss = 0.0616, Train Acc = 0.9767, Train F1 = 0.9653 | Val Loss = 0.0659, Val Acc = 0.9782, Val F1 = 0.9686\n",
      "Epoch 58: Train Loss = 0.0612, Train Acc = 0.9763, Train F1 = 0.9649 | Val Loss = 0.0668, Val Acc = 0.9782, Val F1 = 0.9686\n",
      "Epoch 59: Train Loss = 0.0611, Train Acc = 0.9773, Train F1 = 0.9665 | Val Loss = 0.0661, Val Acc = 0.9745, Val F1 = 0.9635\n",
      "Epoch 60: Train Loss = 0.0615, Train Acc = 0.9754, Train F1 = 0.9635 | Val Loss = 0.0790, Val Acc = 0.9782, Val F1 = 0.9697\n",
      "Epoch 61: Train Loss = 0.0680, Train Acc = 0.9721, Train F1 = 0.9589 | Val Loss = 0.0618, Val Acc = 0.9758, Val F1 = 0.9649\n",
      "Epoch 62: Train Loss = 0.0581, Train Acc = 0.9791, Train F1 = 0.9690 | Val Loss = 0.0663, Val Acc = 0.9855, Val F1 = 0.9793\n",
      "Epoch 63: Train Loss = 0.0636, Train Acc = 0.9754, Train F1 = 0.9639 | Val Loss = 0.0699, Val Acc = 0.9770, Val F1 = 0.9659\n",
      "Epoch 64: Train Loss = 0.0613, Train Acc = 0.9745, Train F1 = 0.9623 | Val Loss = 0.0696, Val Acc = 0.9770, Val F1 = 0.9659\n",
      "Epoch 65: Train Loss = 0.0574, Train Acc = 0.9773, Train F1 = 0.9662 | Val Loss = 0.0628, Val Acc = 0.9855, Val F1 = 0.9791\n",
      "Epoch 66: Train Loss = 0.0571, Train Acc = 0.9779, Train F1 = 0.9672 | Val Loss = 0.0612, Val Acc = 0.9794, Val F1 = 0.9704\n",
      "Epoch 67: Train Loss = 0.0572, Train Acc = 0.9776, Train F1 = 0.9668 | Val Loss = 0.0683, Val Acc = 0.9770, Val F1 = 0.9659\n",
      "Epoch 68: Train Loss = 0.0566, Train Acc = 0.9782, Train F1 = 0.9677 | Val Loss = 0.0658, Val Acc = 0.9782, Val F1 = 0.9686\n",
      "Epoch 69: Train Loss = 0.0581, Train Acc = 0.9773, Train F1 = 0.9664 | Val Loss = 0.0633, Val Acc = 0.9770, Val F1 = 0.9666\n",
      "Epoch 70: Train Loss = 0.0542, Train Acc = 0.9797, Train F1 = 0.9699 | Val Loss = 0.0589, Val Acc = 0.9794, Val F1 = 0.9700\n",
      "Epoch 71: Train Loss = 0.0581, Train Acc = 0.9763, Train F1 = 0.9649 | Val Loss = 0.0658, Val Acc = 0.9782, Val F1 = 0.9678\n",
      "Epoch 72: Train Loss = 0.0527, Train Acc = 0.9815, Train F1 = 0.9727 | Val Loss = 0.0666, Val Acc = 0.9782, Val F1 = 0.9679\n",
      "Epoch 73: Train Loss = 0.0521, Train Acc = 0.9803, Train F1 = 0.9710 | Val Loss = 0.0701, Val Acc = 0.9709, Val F1 = 0.9567\n",
      "Epoch 74: Train Loss = 0.0601, Train Acc = 0.9788, Train F1 = 0.9686 | Val Loss = 0.0718, Val Acc = 0.9697, Val F1 = 0.9550\n",
      "Epoch 75: Train Loss = 0.0552, Train Acc = 0.9803, Train F1 = 0.9710 | Val Loss = 0.0581, Val Acc = 0.9782, Val F1 = 0.9679\n",
      "Epoch 76: Train Loss = 0.0547, Train Acc = 0.9763, Train F1 = 0.9651 | Val Loss = 0.0597, Val Acc = 0.9794, Val F1 = 0.9697\n",
      "Epoch 77: Train Loss = 0.0514, Train Acc = 0.9800, Train F1 = 0.9704 | Val Loss = 0.0605, Val Acc = 0.9855, Val F1 = 0.9792\n",
      "Epoch 78: Train Loss = 0.0518, Train Acc = 0.9782, Train F1 = 0.9678 | Val Loss = 0.0630, Val Acc = 0.9770, Val F1 = 0.9662\n",
      "Epoch 79: Train Loss = 0.0488, Train Acc = 0.9821, Train F1 = 0.9736 | Val Loss = 0.0589, Val Acc = 0.9794, Val F1 = 0.9697\n",
      "Epoch 80: Train Loss = 0.0487, Train Acc = 0.9812, Train F1 = 0.9722 | Val Loss = 0.0555, Val Acc = 0.9855, Val F1 = 0.9793\n",
      "Epoch 81: Train Loss = 0.0492, Train Acc = 0.9824, Train F1 = 0.9741 | Val Loss = 0.0659, Val Acc = 0.9806, Val F1 = 0.9726\n",
      "Epoch 82: Train Loss = 0.0509, Train Acc = 0.9794, Train F1 = 0.9697 | Val Loss = 0.0535, Val Acc = 0.9806, Val F1 = 0.9719\n",
      "Epoch 83: Train Loss = 0.0515, Train Acc = 0.9794, Train F1 = 0.9697 | Val Loss = 0.0566, Val Acc = 0.9782, Val F1 = 0.9682\n",
      "Epoch 84: Train Loss = 0.0602, Train Acc = 0.9751, Train F1 = 0.9632 | Val Loss = 0.0766, Val Acc = 0.9673, Val F1 = 0.9507\n",
      "Epoch 85: Train Loss = 0.0528, Train Acc = 0.9794, Train F1 = 0.9696 | Val Loss = 0.0649, Val Acc = 0.9758, Val F1 = 0.9642\n",
      "Epoch 86: Train Loss = 0.0483, Train Acc = 0.9818, Train F1 = 0.9731 | Val Loss = 0.0647, Val Acc = 0.9770, Val F1 = 0.9660\n",
      "Epoch 87: Train Loss = 0.0488, Train Acc = 0.9812, Train F1 = 0.9722 | Val Loss = 0.0525, Val Acc = 0.9842, Val F1 = 0.9773\n",
      "Epoch 88: Train Loss = 0.0470, Train Acc = 0.9812, Train F1 = 0.9723 | Val Loss = 0.0512, Val Acc = 0.9818, Val F1 = 0.9738\n",
      "Epoch 89: Train Loss = 0.0508, Train Acc = 0.9818, Train F1 = 0.9733 | Val Loss = 0.0574, Val Acc = 0.9770, Val F1 = 0.9662\n",
      "Epoch 90: Train Loss = 0.0498, Train Acc = 0.9833, Train F1 = 0.9755 | Val Loss = 0.0562, Val Acc = 0.9806, Val F1 = 0.9719\n",
      "Epoch 91: Train Loss = 0.0490, Train Acc = 0.9821, Train F1 = 0.9735 | Val Loss = 0.0561, Val Acc = 0.9770, Val F1 = 0.9664\n",
      "Epoch 92: Train Loss = 0.0502, Train Acc = 0.9794, Train F1 = 0.9696 | Val Loss = 0.0517, Val Acc = 0.9794, Val F1 = 0.9701\n",
      "Epoch 93: Train Loss = 0.0478, Train Acc = 0.9824, Train F1 = 0.9741 | Val Loss = 0.0520, Val Acc = 0.9818, Val F1 = 0.9737\n",
      "Epoch 94: Train Loss = 0.0454, Train Acc = 0.9827, Train F1 = 0.9746 | Val Loss = 0.0588, Val Acc = 0.9782, Val F1 = 0.9680\n",
      "Epoch 95: Train Loss = 0.0464, Train Acc = 0.9830, Train F1 = 0.9751 | Val Loss = 0.0541, Val Acc = 0.9782, Val F1 = 0.9684\n",
      "Epoch 96: Train Loss = 0.0465, Train Acc = 0.9830, Train F1 = 0.9751 | Val Loss = 0.0721, Val Acc = 0.9745, Val F1 = 0.9622\n",
      "Epoch 97: Train Loss = 0.0446, Train Acc = 0.9842, Train F1 = 0.9767 | Val Loss = 0.0497, Val Acc = 0.9879, Val F1 = 0.9826\n",
      "Epoch 98: Train Loss = 0.0434, Train Acc = 0.9854, Train F1 = 0.9787 | Val Loss = 0.0519, Val Acc = 0.9855, Val F1 = 0.9790\n",
      "Epoch 99: Train Loss = 0.0432, Train Acc = 0.9836, Train F1 = 0.9757 | Val Loss = 0.0499, Val Acc = 0.9879, Val F1 = 0.9827\n",
      "[np.int64(0), 0.6385135135135135, 0.38969072164948454, 0.0, 0.0]\n",
      "***** Loop 1: ['S9'] *****\n",
      "==========Loading Training set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S16/S16.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S13/S13.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S8/S8.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S4/S4.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S11/S11.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S15/S15.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S3/S3.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S2/S2.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S6/S6.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S7/S7.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S14/S14.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S10/S10.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S5/S5.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S17/S17.pkl\n",
      "(4125, 1000, 1)\n",
      "==========Loading Testing set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S9/S9.pkl\n",
      "Epoch 0: Train Loss = 0.5189, Train Acc = 0.7624, Train F1 = 0.4928 | Val Loss = 0.4215, Val Acc = 0.8303, Val F1 = 0.6587\n",
      "Epoch 1: Train Loss = 0.3614, Train Acc = 0.8552, Train F1 = 0.7126 | Val Loss = 0.3285, Val Acc = 0.8703, Val F1 = 0.7692\n",
      "Epoch 2: Train Loss = 0.2829, Train Acc = 0.8876, Train F1 = 0.8051 | Val Loss = 0.2731, Val Acc = 0.8921, Val F1 = 0.8318\n",
      "Epoch 3: Train Loss = 0.2287, Train Acc = 0.9191, Train F1 = 0.8688 | Val Loss = 0.2263, Val Acc = 0.9042, Val F1 = 0.8487\n",
      "Epoch 4: Train Loss = 0.1930, Train Acc = 0.9252, Train F1 = 0.8805 | Val Loss = 0.1984, Val Acc = 0.9152, Val F1 = 0.8720\n",
      "Epoch 5: Train Loss = 0.1661, Train Acc = 0.9388, Train F1 = 0.9050 | Val Loss = 0.1790, Val Acc = 0.9200, Val F1 = 0.8772\n",
      "Epoch 6: Train Loss = 0.1515, Train Acc = 0.9421, Train F1 = 0.9110 | Val Loss = 0.1634, Val Acc = 0.9261, Val F1 = 0.8863\n",
      "Epoch 7: Train Loss = 0.1444, Train Acc = 0.9452, Train F1 = 0.9150 | Val Loss = 0.1666, Val Acc = 0.9212, Val F1 = 0.8870\n",
      "Epoch 8: Train Loss = 0.1342, Train Acc = 0.9479, Train F1 = 0.9208 | Val Loss = 0.1554, Val Acc = 0.9285, Val F1 = 0.8932\n",
      "Epoch 9: Train Loss = 0.1319, Train Acc = 0.9473, Train F1 = 0.9197 | Val Loss = 0.1430, Val Acc = 0.9345, Val F1 = 0.9008\n",
      "Epoch 10: Train Loss = 0.1237, Train Acc = 0.9533, Train F1 = 0.9286 | Val Loss = 0.1434, Val Acc = 0.9358, Val F1 = 0.9064\n",
      "Epoch 11: Train Loss = 0.1212, Train Acc = 0.9521, Train F1 = 0.9273 | Val Loss = 0.1310, Val Acc = 0.9442, Val F1 = 0.9183\n",
      "Epoch 12: Train Loss = 0.1157, Train Acc = 0.9533, Train F1 = 0.9295 | Val Loss = 0.1242, Val Acc = 0.9455, Val F1 = 0.9186\n",
      "Epoch 13: Train Loss = 0.1116, Train Acc = 0.9555, Train F1 = 0.9326 | Val Loss = 0.1208, Val Acc = 0.9442, Val F1 = 0.9176\n",
      "Epoch 14: Train Loss = 0.1136, Train Acc = 0.9542, Train F1 = 0.9311 | Val Loss = 0.1331, Val Acc = 0.9430, Val F1 = 0.9198\n",
      "Epoch 15: Train Loss = 0.1079, Train Acc = 0.9555, Train F1 = 0.9327 | Val Loss = 0.1148, Val Acc = 0.9467, Val F1 = 0.9212\n",
      "Epoch 16: Train Loss = 0.1044, Train Acc = 0.9582, Train F1 = 0.9371 | Val Loss = 0.1132, Val Acc = 0.9539, Val F1 = 0.9335\n",
      "Epoch 17: Train Loss = 0.1026, Train Acc = 0.9606, Train F1 = 0.9409 | Val Loss = 0.1188, Val Acc = 0.9503, Val F1 = 0.9258\n",
      "Epoch 18: Train Loss = 0.0988, Train Acc = 0.9630, Train F1 = 0.9443 | Val Loss = 0.1061, Val Acc = 0.9539, Val F1 = 0.9330\n",
      "Epoch 19: Train Loss = 0.1010, Train Acc = 0.9567, Train F1 = 0.9350 | Val Loss = 0.1067, Val Acc = 0.9588, Val F1 = 0.9391\n",
      "Epoch 20: Train Loss = 0.0942, Train Acc = 0.9612, Train F1 = 0.9418 | Val Loss = 0.1009, Val Acc = 0.9552, Val F1 = 0.9344\n",
      "Epoch 21: Train Loss = 0.0908, Train Acc = 0.9642, Train F1 = 0.9465 | Val Loss = 0.1001, Val Acc = 0.9624, Val F1 = 0.9465\n",
      "Epoch 22: Train Loss = 0.0903, Train Acc = 0.9682, Train F1 = 0.9528 | Val Loss = 0.0964, Val Acc = 0.9564, Val F1 = 0.9355\n",
      "Epoch 23: Train Loss = 0.0873, Train Acc = 0.9664, Train F1 = 0.9497 | Val Loss = 0.0982, Val Acc = 0.9624, Val F1 = 0.9467\n",
      "Epoch 24: Train Loss = 0.0895, Train Acc = 0.9652, Train F1 = 0.9479 | Val Loss = 0.0982, Val Acc = 0.9636, Val F1 = 0.9467\n",
      "Epoch 25: Train Loss = 0.0882, Train Acc = 0.9679, Train F1 = 0.9522 | Val Loss = 0.0977, Val Acc = 0.9600, Val F1 = 0.9408\n",
      "Epoch 26: Train Loss = 0.0834, Train Acc = 0.9688, Train F1 = 0.9533 | Val Loss = 0.0893, Val Acc = 0.9636, Val F1 = 0.9469\n",
      "Epoch 27: Train Loss = 0.0829, Train Acc = 0.9682, Train F1 = 0.9525 | Val Loss = 0.0904, Val Acc = 0.9624, Val F1 = 0.9453\n",
      "Epoch 28: Train Loss = 0.0805, Train Acc = 0.9691, Train F1 = 0.9539 | Val Loss = 0.0860, Val Acc = 0.9624, Val F1 = 0.9459\n",
      "Epoch 29: Train Loss = 0.0807, Train Acc = 0.9679, Train F1 = 0.9523 | Val Loss = 0.0997, Val Acc = 0.9503, Val F1 = 0.9249\n",
      "Epoch 30: Train Loss = 0.0788, Train Acc = 0.9688, Train F1 = 0.9538 | Val Loss = 0.0837, Val Acc = 0.9636, Val F1 = 0.9475\n",
      "Epoch 31: Train Loss = 0.0792, Train Acc = 0.9694, Train F1 = 0.9546 | Val Loss = 0.0828, Val Acc = 0.9661, Val F1 = 0.9514\n",
      "Epoch 32: Train Loss = 0.0759, Train Acc = 0.9724, Train F1 = 0.9590 | Val Loss = 0.0885, Val Acc = 0.9636, Val F1 = 0.9461\n",
      "Epoch 33: Train Loss = 0.0766, Train Acc = 0.9709, Train F1 = 0.9566 | Val Loss = 0.0802, Val Acc = 0.9648, Val F1 = 0.9494\n",
      "Epoch 34: Train Loss = 0.0777, Train Acc = 0.9706, Train F1 = 0.9563 | Val Loss = 0.0886, Val Acc = 0.9673, Val F1 = 0.9544\n",
      "Epoch 35: Train Loss = 0.0717, Train Acc = 0.9712, Train F1 = 0.9572 | Val Loss = 0.0813, Val Acc = 0.9697, Val F1 = 0.9570\n",
      "Epoch 36: Train Loss = 0.0707, Train Acc = 0.9721, Train F1 = 0.9586 | Val Loss = 0.0816, Val Acc = 0.9673, Val F1 = 0.9519\n",
      "Epoch 37: Train Loss = 0.0702, Train Acc = 0.9745, Train F1 = 0.9624 | Val Loss = 0.0819, Val Acc = 0.9636, Val F1 = 0.9469\n",
      "Epoch 38: Train Loss = 0.0699, Train Acc = 0.9736, Train F1 = 0.9609 | Val Loss = 0.0845, Val Acc = 0.9636, Val F1 = 0.9465\n",
      "Epoch 39: Train Loss = 0.0709, Train Acc = 0.9712, Train F1 = 0.9570 | Val Loss = 0.0736, Val Acc = 0.9709, Val F1 = 0.9579\n",
      "Epoch 40: Train Loss = 0.0733, Train Acc = 0.9712, Train F1 = 0.9575 | Val Loss = 0.0775, Val Acc = 0.9709, Val F1 = 0.9584\n",
      "Epoch 41: Train Loss = 0.0654, Train Acc = 0.9721, Train F1 = 0.9588 | Val Loss = 0.0765, Val Acc = 0.9685, Val F1 = 0.9556\n",
      "Epoch 42: Train Loss = 0.0658, Train Acc = 0.9752, Train F1 = 0.9632 | Val Loss = 0.0860, Val Acc = 0.9588, Val F1 = 0.9391\n",
      "Epoch 43: Train Loss = 0.0668, Train Acc = 0.9712, Train F1 = 0.9574 | Val Loss = 0.0764, Val Acc = 0.9709, Val F1 = 0.9582\n",
      "Epoch 44: Train Loss = 0.0643, Train Acc = 0.9742, Train F1 = 0.9620 | Val Loss = 0.0740, Val Acc = 0.9673, Val F1 = 0.9519\n",
      "Epoch 45: Train Loss = 0.0616, Train Acc = 0.9755, Train F1 = 0.9635 | Val Loss = 0.0684, Val Acc = 0.9782, Val F1 = 0.9693\n",
      "Epoch 46: Train Loss = 0.0689, Train Acc = 0.9745, Train F1 = 0.9623 | Val Loss = 0.0820, Val Acc = 0.9673, Val F1 = 0.9548\n",
      "Epoch 47: Train Loss = 0.0646, Train Acc = 0.9755, Train F1 = 0.9637 | Val Loss = 0.0675, Val Acc = 0.9721, Val F1 = 0.9597\n",
      "Epoch 48: Train Loss = 0.0628, Train Acc = 0.9739, Train F1 = 0.9613 | Val Loss = 0.0663, Val Acc = 0.9782, Val F1 = 0.9684\n",
      "Epoch 49: Train Loss = 0.0599, Train Acc = 0.9782, Train F1 = 0.9676 | Val Loss = 0.0663, Val Acc = 0.9770, Val F1 = 0.9670\n",
      "Epoch 50: Train Loss = 0.0592, Train Acc = 0.9773, Train F1 = 0.9664 | Val Loss = 0.0642, Val Acc = 0.9782, Val F1 = 0.9688\n",
      "Epoch 51: Train Loss = 0.0587, Train Acc = 0.9779, Train F1 = 0.9673 | Val Loss = 0.0659, Val Acc = 0.9733, Val F1 = 0.9618\n",
      "Epoch 52: Train Loss = 0.0593, Train Acc = 0.9752, Train F1 = 0.9632 | Val Loss = 0.0773, Val Acc = 0.9685, Val F1 = 0.9536\n",
      "Epoch 53: Train Loss = 0.0601, Train Acc = 0.9755, Train F1 = 0.9637 | Val Loss = 0.0850, Val Acc = 0.9612, Val F1 = 0.9427\n",
      "Epoch 54: Train Loss = 0.0703, Train Acc = 0.9676, Train F1 = 0.9517 | Val Loss = 0.0764, Val Acc = 0.9721, Val F1 = 0.9608\n",
      "Epoch 55: Train Loss = 0.0601, Train Acc = 0.9745, Train F1 = 0.9625 | Val Loss = 0.0615, Val Acc = 0.9770, Val F1 = 0.9670\n",
      "Epoch 56: Train Loss = 0.0549, Train Acc = 0.9788, Train F1 = 0.9685 | Val Loss = 0.0618, Val Acc = 0.9794, Val F1 = 0.9707\n",
      "Epoch 57: Train Loss = 0.0542, Train Acc = 0.9806, Train F1 = 0.9713 | Val Loss = 0.0644, Val Acc = 0.9770, Val F1 = 0.9666\n",
      "Epoch 58: Train Loss = 0.0563, Train Acc = 0.9770, Train F1 = 0.9660 | Val Loss = 0.0653, Val Acc = 0.9745, Val F1 = 0.9632\n",
      "Epoch 59: Train Loss = 0.0629, Train Acc = 0.9755, Train F1 = 0.9639 | Val Loss = 0.0693, Val Acc = 0.9733, Val F1 = 0.9625\n",
      "Epoch 60: Train Loss = 0.0587, Train Acc = 0.9742, Train F1 = 0.9620 | Val Loss = 0.0675, Val Acc = 0.9745, Val F1 = 0.9628\n",
      "Epoch 61: Train Loss = 0.0607, Train Acc = 0.9739, Train F1 = 0.9616 | Val Loss = 0.0657, Val Acc = 0.9758, Val F1 = 0.9648\n",
      "Epoch 62: Train Loss = 0.0537, Train Acc = 0.9770, Train F1 = 0.9658 | Val Loss = 0.0799, Val Acc = 0.9636, Val F1 = 0.9503\n",
      "Epoch 63: Train Loss = 0.0636, Train Acc = 0.9739, Train F1 = 0.9616 | Val Loss = 0.0615, Val Acc = 0.9794, Val F1 = 0.9710\n",
      "Epoch 64: Train Loss = 0.0619, Train Acc = 0.9779, Train F1 = 0.9675 | Val Loss = 0.0636, Val Acc = 0.9745, Val F1 = 0.9642\n",
      "Epoch 65: Train Loss = 0.0545, Train Acc = 0.9791, Train F1 = 0.9693 | Val Loss = 0.0701, Val Acc = 0.9697, Val F1 = 0.9555\n",
      "Epoch 66: Train Loss = 0.0652, Train Acc = 0.9712, Train F1 = 0.9578 | Val Loss = 0.0853, Val Acc = 0.9588, Val F1 = 0.9381\n",
      "Epoch 67: Train Loss = 0.0529, Train Acc = 0.9773, Train F1 = 0.9664 | Val Loss = 0.0651, Val Acc = 0.9745, Val F1 = 0.9644\n",
      "Epoch 68: Train Loss = 0.0505, Train Acc = 0.9830, Train F1 = 0.9750 | Val Loss = 0.0542, Val Acc = 0.9818, Val F1 = 0.9740\n",
      "Epoch 69: Train Loss = 0.0530, Train Acc = 0.9797, Train F1 = 0.9702 | Val Loss = 0.0562, Val Acc = 0.9782, Val F1 = 0.9686\n",
      "Epoch 70: Train Loss = 0.0490, Train Acc = 0.9815, Train F1 = 0.9727 | Val Loss = 0.0533, Val Acc = 0.9818, Val F1 = 0.9740\n",
      "Epoch 71: Train Loss = 0.0487, Train Acc = 0.9800, Train F1 = 0.9705 | Val Loss = 0.0541, Val Acc = 0.9830, Val F1 = 0.9758\n",
      "Epoch 72: Train Loss = 0.0487, Train Acc = 0.9800, Train F1 = 0.9704 | Val Loss = 0.0537, Val Acc = 0.9830, Val F1 = 0.9761\n",
      "Epoch 73: Train Loss = 0.0491, Train Acc = 0.9815, Train F1 = 0.9728 | Val Loss = 0.0558, Val Acc = 0.9830, Val F1 = 0.9761\n",
      "Epoch 74: Train Loss = 0.0486, Train Acc = 0.9812, Train F1 = 0.9723 | Val Loss = 0.0521, Val Acc = 0.9830, Val F1 = 0.9757\n",
      "Epoch 75: Train Loss = 0.0503, Train Acc = 0.9791, Train F1 = 0.9693 | Val Loss = 0.0606, Val Acc = 0.9770, Val F1 = 0.9666\n",
      "Epoch 76: Train Loss = 0.0559, Train Acc = 0.9755, Train F1 = 0.9641 | Val Loss = 0.0835, Val Acc = 0.9685, Val F1 = 0.9534\n",
      "Epoch 77: Train Loss = 0.0530, Train Acc = 0.9785, Train F1 = 0.9682 | Val Loss = 0.0591, Val Acc = 0.9794, Val F1 = 0.9703\n",
      "Epoch 78: Train Loss = 0.0475, Train Acc = 0.9839, Train F1 = 0.9763 | Val Loss = 0.0547, Val Acc = 0.9818, Val F1 = 0.9740\n",
      "Epoch 79: Train Loss = 0.0469, Train Acc = 0.9803, Train F1 = 0.9710 | Val Loss = 0.0608, Val Acc = 0.9733, Val F1 = 0.9624\n",
      "Epoch 80: Train Loss = 0.0495, Train Acc = 0.9824, Train F1 = 0.9741 | Val Loss = 0.0539, Val Acc = 0.9806, Val F1 = 0.9724\n",
      "Epoch 81: Train Loss = 0.0479, Train Acc = 0.9812, Train F1 = 0.9723 | Val Loss = 0.0561, Val Acc = 0.9794, Val F1 = 0.9711\n",
      "Epoch 82: Train Loss = 0.0462, Train Acc = 0.9833, Train F1 = 0.9755 | Val Loss = 0.0636, Val Acc = 0.9782, Val F1 = 0.9685\n",
      "Epoch 83: Train Loss = 0.0498, Train Acc = 0.9803, Train F1 = 0.9711 | Val Loss = 0.0633, Val Acc = 0.9758, Val F1 = 0.9648\n",
      "Epoch 84: Train Loss = 0.0474, Train Acc = 0.9800, Train F1 = 0.9706 | Val Loss = 0.0513, Val Acc = 0.9867, Val F1 = 0.9811\n",
      "Epoch 85: Train Loss = 0.0445, Train Acc = 0.9836, Train F1 = 0.9760 | Val Loss = 0.0679, Val Acc = 0.9697, Val F1 = 0.9555\n",
      "Epoch 86: Train Loss = 0.0476, Train Acc = 0.9818, Train F1 = 0.9731 | Val Loss = 0.0499, Val Acc = 0.9818, Val F1 = 0.9739\n",
      "Epoch 87: Train Loss = 0.0448, Train Acc = 0.9830, Train F1 = 0.9750 | Val Loss = 0.0528, Val Acc = 0.9806, Val F1 = 0.9726\n",
      "Epoch 88: Train Loss = 0.0444, Train Acc = 0.9852, Train F1 = 0.9781 | Val Loss = 0.0510, Val Acc = 0.9842, Val F1 = 0.9779\n",
      "Epoch 89: Train Loss = 0.0432, Train Acc = 0.9821, Train F1 = 0.9738 | Val Loss = 0.0497, Val Acc = 0.9818, Val F1 = 0.9738\n",
      "Epoch 90: Train Loss = 0.0433, Train Acc = 0.9861, Train F1 = 0.9795 | Val Loss = 0.0602, Val Acc = 0.9745, Val F1 = 0.9629\n",
      "Epoch 91: Train Loss = 0.0449, Train Acc = 0.9830, Train F1 = 0.9750 | Val Loss = 0.0461, Val Acc = 0.9867, Val F1 = 0.9811\n",
      "Epoch 92: Train Loss = 0.0488, Train Acc = 0.9803, Train F1 = 0.9711 | Val Loss = 0.0695, Val Acc = 0.9709, Val F1 = 0.9574\n",
      "Epoch 93: Train Loss = 0.0573, Train Acc = 0.9764, Train F1 = 0.9653 | Val Loss = 0.0662, Val Acc = 0.9709, Val F1 = 0.9591\n",
      "Epoch 94: Train Loss = 0.0436, Train Acc = 0.9839, Train F1 = 0.9764 | Val Loss = 0.0606, Val Acc = 0.9758, Val F1 = 0.9646\n",
      "Epoch 95: Train Loss = 0.0422, Train Acc = 0.9855, Train F1 = 0.9786 | Val Loss = 0.0582, Val Acc = 0.9794, Val F1 = 0.9707\n",
      "Epoch 96: Train Loss = 0.0432, Train Acc = 0.9845, Train F1 = 0.9772 | Val Loss = 0.0494, Val Acc = 0.9830, Val F1 = 0.9760\n",
      "Epoch 97: Train Loss = 0.0419, Train Acc = 0.9836, Train F1 = 0.9759 | Val Loss = 0.0473, Val Acc = 0.9855, Val F1 = 0.9792\n",
      "Epoch 98: Train Loss = 0.0412, Train Acc = 0.9845, Train F1 = 0.9773 | Val Loss = 0.0469, Val Acc = 0.9855, Val F1 = 0.9793\n",
      "Epoch 99: Train Loss = 0.0444, Train Acc = 0.9836, Train F1 = 0.9759 | Val Loss = 0.0464, Val Acc = 0.9867, Val F1 = 0.9811\n",
      "[np.int64(1), 0.38095238095238093, 0.3802353595255745, 0.9682539682539683, 0.25311203319502074]\n",
      "***** Loop 2: ['S13'] *****\n",
      "==========Loading Training set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S16/S16.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S9/S9.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S8/S8.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S4/S4.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S11/S11.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S15/S15.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S3/S3.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S2/S2.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S6/S6.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S7/S7.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S14/S14.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S10/S10.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S5/S5.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S17/S17.pkl\n",
      "(4122, 1000, 1)\n",
      "==========Loading Testing set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S13/S13.pkl\n",
      "Epoch 0: Train Loss = 0.5119, Train Acc = 0.7913, Train F1 = 0.4930 | Val Loss = 0.4532, Val Acc = 0.8230, Val F1 = 0.6667\n",
      "Epoch 1: Train Loss = 0.3753, Train Acc = 0.8556, Train F1 = 0.7073 | Val Loss = 0.3621, Val Acc = 0.8642, Val F1 = 0.7695\n",
      "Epoch 2: Train Loss = 0.3021, Train Acc = 0.8817, Train F1 = 0.7866 | Val Loss = 0.3099, Val Acc = 0.8873, Val F1 = 0.8389\n",
      "Epoch 3: Train Loss = 0.2580, Train Acc = 0.8941, Train F1 = 0.8223 | Val Loss = 0.2596, Val Acc = 0.8994, Val F1 = 0.8486\n",
      "Epoch 4: Train Loss = 0.2206, Train Acc = 0.9175, Train F1 = 0.8639 | Val Loss = 0.2314, Val Acc = 0.9115, Val F1 = 0.8668\n",
      "Epoch 5: Train Loss = 0.1970, Train Acc = 0.9260, Train F1 = 0.8788 | Val Loss = 0.2127, Val Acc = 0.9152, Val F1 = 0.8808\n",
      "Epoch 6: Train Loss = 0.1771, Train Acc = 0.9342, Train F1 = 0.8941 | Val Loss = 0.1991, Val Acc = 0.9236, Val F1 = 0.8850\n",
      "Epoch 7: Train Loss = 0.1667, Train Acc = 0.9369, Train F1 = 0.9000 | Val Loss = 0.1899, Val Acc = 0.9261, Val F1 = 0.8892\n",
      "Epoch 8: Train Loss = 0.1580, Train Acc = 0.9378, Train F1 = 0.9010 | Val Loss = 0.1770, Val Acc = 0.9285, Val F1 = 0.9001\n",
      "Epoch 9: Train Loss = 0.1477, Train Acc = 0.9384, Train F1 = 0.9030 | Val Loss = 0.1676, Val Acc = 0.9370, Val F1 = 0.9069\n",
      "Epoch 10: Train Loss = 0.1404, Train Acc = 0.9436, Train F1 = 0.9110 | Val Loss = 0.1606, Val Acc = 0.9321, Val F1 = 0.9005\n",
      "Epoch 11: Train Loss = 0.1345, Train Acc = 0.9466, Train F1 = 0.9158 | Val Loss = 0.1507, Val Acc = 0.9394, Val F1 = 0.9148\n",
      "Epoch 12: Train Loss = 0.1275, Train Acc = 0.9493, Train F1 = 0.9200 | Val Loss = 0.1428, Val Acc = 0.9491, Val F1 = 0.9290\n",
      "Epoch 13: Train Loss = 0.1262, Train Acc = 0.9551, Train F1 = 0.9304 | Val Loss = 0.1436, Val Acc = 0.9418, Val F1 = 0.9182\n",
      "Epoch 14: Train Loss = 0.1255, Train Acc = 0.9475, Train F1 = 0.9189 | Val Loss = 0.1509, Val Acc = 0.9358, Val F1 = 0.9057\n",
      "Epoch 15: Train Loss = 0.1227, Train Acc = 0.9524, Train F1 = 0.9268 | Val Loss = 0.1373, Val Acc = 0.9442, Val F1 = 0.9192\n",
      "Epoch 16: Train Loss = 0.1117, Train Acc = 0.9575, Train F1 = 0.9347 | Val Loss = 0.1278, Val Acc = 0.9636, Val F1 = 0.9491\n",
      "Epoch 17: Train Loss = 0.1139, Train Acc = 0.9542, Train F1 = 0.9290 | Val Loss = 0.1276, Val Acc = 0.9539, Val F1 = 0.9343\n",
      "Epoch 18: Train Loss = 0.1086, Train Acc = 0.9609, Train F1 = 0.9405 | Val Loss = 0.1212, Val Acc = 0.9552, Val F1 = 0.9371\n",
      "Epoch 19: Train Loss = 0.1040, Train Acc = 0.9588, Train F1 = 0.9367 | Val Loss = 0.1167, Val Acc = 0.9636, Val F1 = 0.9493\n",
      "Epoch 20: Train Loss = 0.1010, Train Acc = 0.9627, Train F1 = 0.9429 | Val Loss = 0.1151, Val Acc = 0.9600, Val F1 = 0.9435\n",
      "Epoch 21: Train Loss = 0.0971, Train Acc = 0.9624, Train F1 = 0.9428 | Val Loss = 0.1251, Val Acc = 0.9491, Val F1 = 0.9268\n",
      "Epoch 22: Train Loss = 0.0978, Train Acc = 0.9633, Train F1 = 0.9439 | Val Loss = 0.1157, Val Acc = 0.9552, Val F1 = 0.9364\n",
      "Epoch 23: Train Loss = 0.0939, Train Acc = 0.9645, Train F1 = 0.9459 | Val Loss = 0.1249, Val Acc = 0.9479, Val F1 = 0.9250\n",
      "Epoch 24: Train Loss = 0.0930, Train Acc = 0.9660, Train F1 = 0.9483 | Val Loss = 0.1040, Val Acc = 0.9612, Val F1 = 0.9459\n",
      "Epoch 25: Train Loss = 0.0902, Train Acc = 0.9654, Train F1 = 0.9474 | Val Loss = 0.1055, Val Acc = 0.9636, Val F1 = 0.9489\n",
      "Epoch 26: Train Loss = 0.0873, Train Acc = 0.9669, Train F1 = 0.9498 | Val Loss = 0.1039, Val Acc = 0.9624, Val F1 = 0.9471\n",
      "Epoch 27: Train Loss = 0.0885, Train Acc = 0.9648, Train F1 = 0.9466 | Val Loss = 0.1276, Val Acc = 0.9527, Val F1 = 0.9319\n",
      "Epoch 28: Train Loss = 0.0961, Train Acc = 0.9642, Train F1 = 0.9457 | Val Loss = 0.1027, Val Acc = 0.9636, Val F1 = 0.9489\n",
      "Epoch 29: Train Loss = 0.0832, Train Acc = 0.9694, Train F1 = 0.9538 | Val Loss = 0.1019, Val Acc = 0.9624, Val F1 = 0.9471\n",
      "Epoch 30: Train Loss = 0.0835, Train Acc = 0.9660, Train F1 = 0.9485 | Val Loss = 0.0928, Val Acc = 0.9661, Val F1 = 0.9530\n",
      "Epoch 31: Train Loss = 0.0817, Train Acc = 0.9663, Train F1 = 0.9492 | Val Loss = 0.1095, Val Acc = 0.9539, Val F1 = 0.9338\n",
      "Epoch 32: Train Loss = 0.0813, Train Acc = 0.9672, Train F1 = 0.9504 | Val Loss = 0.1118, Val Acc = 0.9515, Val F1 = 0.9324\n",
      "Epoch 33: Train Loss = 0.0785, Train Acc = 0.9691, Train F1 = 0.9532 | Val Loss = 0.0893, Val Acc = 0.9685, Val F1 = 0.9563\n",
      "Epoch 34: Train Loss = 0.0739, Train Acc = 0.9712, Train F1 = 0.9567 | Val Loss = 0.1221, Val Acc = 0.9479, Val F1 = 0.9241\n",
      "Epoch 35: Train Loss = 0.0793, Train Acc = 0.9706, Train F1 = 0.9554 | Val Loss = 0.0902, Val Acc = 0.9697, Val F1 = 0.9578\n",
      "Epoch 36: Train Loss = 0.0739, Train Acc = 0.9709, Train F1 = 0.9563 | Val Loss = 0.1134, Val Acc = 0.9600, Val F1 = 0.9433\n",
      "Epoch 37: Train Loss = 0.0759, Train Acc = 0.9709, Train F1 = 0.9562 | Val Loss = 0.0891, Val Acc = 0.9648, Val F1 = 0.9509\n",
      "Epoch 38: Train Loss = 0.0716, Train Acc = 0.9733, Train F1 = 0.9595 | Val Loss = 0.0855, Val Acc = 0.9673, Val F1 = 0.9541\n",
      "Epoch 39: Train Loss = 0.0679, Train Acc = 0.9751, Train F1 = 0.9626 | Val Loss = 0.0834, Val Acc = 0.9685, Val F1 = 0.9574\n",
      "Epoch 40: Train Loss = 0.0702, Train Acc = 0.9733, Train F1 = 0.9597 | Val Loss = 0.0817, Val Acc = 0.9673, Val F1 = 0.9544\n",
      "Epoch 41: Train Loss = 0.0679, Train Acc = 0.9742, Train F1 = 0.9610 | Val Loss = 0.0818, Val Acc = 0.9648, Val F1 = 0.9511\n",
      "Epoch 42: Train Loss = 0.0696, Train Acc = 0.9733, Train F1 = 0.9598 | Val Loss = 0.0778, Val Acc = 0.9697, Val F1 = 0.9584\n",
      "Epoch 43: Train Loss = 0.0656, Train Acc = 0.9733, Train F1 = 0.9601 | Val Loss = 0.0817, Val Acc = 0.9721, Val F1 = 0.9610\n",
      "Epoch 44: Train Loss = 0.0676, Train Acc = 0.9718, Train F1 = 0.9577 | Val Loss = 0.0831, Val Acc = 0.9636, Val F1 = 0.9487\n",
      "Epoch 45: Train Loss = 0.0649, Train Acc = 0.9754, Train F1 = 0.9629 | Val Loss = 0.0781, Val Acc = 0.9697, Val F1 = 0.9575\n",
      "Epoch 46: Train Loss = 0.0666, Train Acc = 0.9727, Train F1 = 0.9589 | Val Loss = 0.0837, Val Acc = 0.9661, Val F1 = 0.9521\n",
      "Epoch 47: Train Loss = 0.0632, Train Acc = 0.9779, Train F1 = 0.9668 | Val Loss = 0.0750, Val Acc = 0.9721, Val F1 = 0.9610\n",
      "Epoch 48: Train Loss = 0.0625, Train Acc = 0.9766, Train F1 = 0.9648 | Val Loss = 0.0744, Val Acc = 0.9685, Val F1 = 0.9562\n",
      "Epoch 49: Train Loss = 0.0621, Train Acc = 0.9757, Train F1 = 0.9635 | Val Loss = 0.0723, Val Acc = 0.9733, Val F1 = 0.9628\n",
      "Epoch 50: Train Loss = 0.0633, Train Acc = 0.9763, Train F1 = 0.9646 | Val Loss = 0.1036, Val Acc = 0.9564, Val F1 = 0.9373\n",
      "Epoch 51: Train Loss = 0.0607, Train Acc = 0.9773, Train F1 = 0.9659 | Val Loss = 0.0752, Val Acc = 0.9697, Val F1 = 0.9588\n",
      "Epoch 52: Train Loss = 0.0641, Train Acc = 0.9760, Train F1 = 0.9640 | Val Loss = 0.0797, Val Acc = 0.9636, Val F1 = 0.9491\n",
      "Epoch 53: Train Loss = 0.0598, Train Acc = 0.9785, Train F1 = 0.9674 | Val Loss = 0.0706, Val Acc = 0.9758, Val F1 = 0.9664\n",
      "Epoch 54: Train Loss = 0.0580, Train Acc = 0.9782, Train F1 = 0.9672 | Val Loss = 0.0679, Val Acc = 0.9782, Val F1 = 0.9698\n",
      "Epoch 55: Train Loss = 0.0581, Train Acc = 0.9788, Train F1 = 0.9682 | Val Loss = 0.0691, Val Acc = 0.9733, Val F1 = 0.9635\n",
      "Epoch 56: Train Loss = 0.0567, Train Acc = 0.9773, Train F1 = 0.9658 | Val Loss = 0.0716, Val Acc = 0.9709, Val F1 = 0.9594\n",
      "Epoch 57: Train Loss = 0.0593, Train Acc = 0.9779, Train F1 = 0.9667 | Val Loss = 0.0667, Val Acc = 0.9758, Val F1 = 0.9663\n",
      "Epoch 58: Train Loss = 0.0551, Train Acc = 0.9812, Train F1 = 0.9717 | Val Loss = 0.0663, Val Acc = 0.9709, Val F1 = 0.9597\n",
      "Epoch 59: Train Loss = 0.0550, Train Acc = 0.9788, Train F1 = 0.9683 | Val Loss = 0.0825, Val Acc = 0.9624, Val F1 = 0.9467\n",
      "Epoch 60: Train Loss = 0.0539, Train Acc = 0.9812, Train F1 = 0.9719 | Val Loss = 0.0746, Val Acc = 0.9685, Val F1 = 0.9557\n",
      "Epoch 61: Train Loss = 0.0566, Train Acc = 0.9785, Train F1 = 0.9677 | Val Loss = 0.0956, Val Acc = 0.9624, Val F1 = 0.9467\n",
      "Epoch 62: Train Loss = 0.0578, Train Acc = 0.9779, Train F1 = 0.9669 | Val Loss = 0.0756, Val Acc = 0.9685, Val F1 = 0.9557\n",
      "Epoch 63: Train Loss = 0.0560, Train Acc = 0.9785, Train F1 = 0.9676 | Val Loss = 0.0684, Val Acc = 0.9697, Val F1 = 0.9575\n",
      "Epoch 64: Train Loss = 0.0525, Train Acc = 0.9794, Train F1 = 0.9690 | Val Loss = 0.0625, Val Acc = 0.9745, Val F1 = 0.9649\n",
      "Epoch 65: Train Loss = 0.0530, Train Acc = 0.9803, Train F1 = 0.9705 | Val Loss = 0.0617, Val Acc = 0.9770, Val F1 = 0.9682\n",
      "Epoch 66: Train Loss = 0.0523, Train Acc = 0.9812, Train F1 = 0.9718 | Val Loss = 0.0625, Val Acc = 0.9818, Val F1 = 0.9754\n",
      "Epoch 67: Train Loss = 0.0509, Train Acc = 0.9821, Train F1 = 0.9732 | Val Loss = 0.0582, Val Acc = 0.9794, Val F1 = 0.9716\n",
      "Epoch 68: Train Loss = 0.0486, Train Acc = 0.9827, Train F1 = 0.9740 | Val Loss = 0.0619, Val Acc = 0.9709, Val F1 = 0.9594\n",
      "Epoch 69: Train Loss = 0.0479, Train Acc = 0.9830, Train F1 = 0.9746 | Val Loss = 0.0717, Val Acc = 0.9685, Val F1 = 0.9559\n",
      "Epoch 70: Train Loss = 0.0498, Train Acc = 0.9833, Train F1 = 0.9750 | Val Loss = 0.0615, Val Acc = 0.9758, Val F1 = 0.9674\n",
      "Epoch 71: Train Loss = 0.0531, Train Acc = 0.9806, Train F1 = 0.9710 | Val Loss = 0.0587, Val Acc = 0.9818, Val F1 = 0.9753\n",
      "Epoch 72: Train Loss = 0.0467, Train Acc = 0.9830, Train F1 = 0.9745 | Val Loss = 0.0586, Val Acc = 0.9758, Val F1 = 0.9669\n",
      "Epoch 73: Train Loss = 0.0471, Train Acc = 0.9848, Train F1 = 0.9773 | Val Loss = 0.0604, Val Acc = 0.9782, Val F1 = 0.9698\n",
      "Epoch 74: Train Loss = 0.0479, Train Acc = 0.9836, Train F1 = 0.9755 | Val Loss = 0.0643, Val Acc = 0.9648, Val F1 = 0.9505\n",
      "Epoch 75: Train Loss = 0.0486, Train Acc = 0.9797, Train F1 = 0.9696 | Val Loss = 0.0597, Val Acc = 0.9770, Val F1 = 0.9685\n",
      "Epoch 76: Train Loss = 0.0535, Train Acc = 0.9794, Train F1 = 0.9691 | Val Loss = 0.0601, Val Acc = 0.9855, Val F1 = 0.9804\n",
      "Epoch 77: Train Loss = 0.0540, Train Acc = 0.9797, Train F1 = 0.9696 | Val Loss = 0.0557, Val Acc = 0.9758, Val F1 = 0.9667\n",
      "Epoch 78: Train Loss = 0.0441, Train Acc = 0.9854, Train F1 = 0.9783 | Val Loss = 0.0629, Val Acc = 0.9721, Val F1 = 0.9610\n",
      "Epoch 79: Train Loss = 0.0445, Train Acc = 0.9854, Train F1 = 0.9782 | Val Loss = 0.0609, Val Acc = 0.9745, Val F1 = 0.9646\n",
      "Epoch 80: Train Loss = 0.0437, Train Acc = 0.9842, Train F1 = 0.9764 | Val Loss = 0.0565, Val Acc = 0.9770, Val F1 = 0.9683\n",
      "Epoch 81: Train Loss = 0.0452, Train Acc = 0.9845, Train F1 = 0.9770 | Val Loss = 0.0643, Val Acc = 0.9697, Val F1 = 0.9575\n",
      "Epoch 82: Train Loss = 0.0463, Train Acc = 0.9845, Train F1 = 0.9767 | Val Loss = 0.0583, Val Acc = 0.9758, Val F1 = 0.9669\n",
      "Epoch 83: Train Loss = 0.0480, Train Acc = 0.9812, Train F1 = 0.9719 | Val Loss = 0.0632, Val Acc = 0.9685, Val F1 = 0.9577\n",
      "Epoch 84: Train Loss = 0.0447, Train Acc = 0.9836, Train F1 = 0.9755 | Val Loss = 0.0558, Val Acc = 0.9806, Val F1 = 0.9733\n",
      "Epoch 85: Train Loss = 0.0445, Train Acc = 0.9821, Train F1 = 0.9733 | Val Loss = 0.0556, Val Acc = 0.9758, Val F1 = 0.9663\n",
      "Epoch 86: Train Loss = 0.0431, Train Acc = 0.9839, Train F1 = 0.9761 | Val Loss = 0.0667, Val Acc = 0.9648, Val F1 = 0.9505\n",
      "Epoch 87: Train Loss = 0.0462, Train Acc = 0.9803, Train F1 = 0.9704 | Val Loss = 0.0716, Val Acc = 0.9648, Val F1 = 0.9503\n",
      "Epoch 88: Train Loss = 0.0442, Train Acc = 0.9860, Train F1 = 0.9791 | Val Loss = 0.0536, Val Acc = 0.9818, Val F1 = 0.9750\n",
      "Epoch 89: Train Loss = 0.0458, Train Acc = 0.9827, Train F1 = 0.9742 | Val Loss = 0.0594, Val Acc = 0.9733, Val F1 = 0.9629\n",
      "Epoch 90: Train Loss = 0.0497, Train Acc = 0.9794, Train F1 = 0.9693 | Val Loss = 0.0595, Val Acc = 0.9685, Val F1 = 0.9559\n",
      "Epoch 91: Train Loss = 0.0452, Train Acc = 0.9821, Train F1 = 0.9735 | Val Loss = 0.0585, Val Acc = 0.9733, Val F1 = 0.9631\n",
      "Epoch 92: Train Loss = 0.0449, Train Acc = 0.9827, Train F1 = 0.9742 | Val Loss = 0.0563, Val Acc = 0.9830, Val F1 = 0.9771\n",
      "Epoch 93: Train Loss = 0.0418, Train Acc = 0.9876, Train F1 = 0.9814 | Val Loss = 0.0514, Val Acc = 0.9782, Val F1 = 0.9702\n",
      "Epoch 94: Train Loss = 0.0390, Train Acc = 0.9879, Train F1 = 0.9820 | Val Loss = 0.0823, Val Acc = 0.9636, Val F1 = 0.9485\n",
      "Epoch 95: Train Loss = 0.0414, Train Acc = 0.9854, Train F1 = 0.9783 | Val Loss = 0.0533, Val Acc = 0.9782, Val F1 = 0.9698\n",
      "Epoch 96: Train Loss = 0.0408, Train Acc = 0.9873, Train F1 = 0.9810 | Val Loss = 0.0518, Val Acc = 0.9806, Val F1 = 0.9735\n",
      "Epoch 97: Train Loss = 0.0414, Train Acc = 0.9845, Train F1 = 0.9768 | Val Loss = 0.0511, Val Acc = 0.9770, Val F1 = 0.9682\n",
      "Epoch 98: Train Loss = 0.0391, Train Acc = 0.9864, Train F1 = 0.9796 | Val Loss = 0.0507, Val Acc = 0.9770, Val F1 = 0.9683\n",
      "Epoch 99: Train Loss = 0.0419, Train Acc = 0.9839, Train F1 = 0.9761 | Val Loss = 0.0871, Val Acc = 0.9648, Val F1 = 0.9503\n",
      "[np.int64(2), 0.8215488215488216, 0.604586902459243, 0.18461538461538463, 1.0]\n",
      "***** Loop 3: ['S8'] *****\n",
      "==========Loading Training set============\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S16/S16.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S9/S9.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S13/S13.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S4/S4.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S11/S11.pkl\n",
      "Working with: /home/van/NamQuang/Dataset/WESAD_LOSO/S15/S15.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0x80 in position 3: ordinal not in range(128)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m accuracy_ls, f1_score_ls, recall_score_ls, precision_score_ls \u001b[38;5;241m=\u001b[39m \u001b[43mloso_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/van/NamQuang/Dataset/WESAD_LOSO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest_loso.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m, in \u001b[0;36mloso_training\u001b[0;34m(root_dir, sample_rate, test_size, filename, load_file)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***** Loop \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m *****\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mload_wesad_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ECGClassificationDataset(X_train, y_train)\n\u001b[1;32m     21\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m ECGClassificationDataset(X_test, y_test)\n",
      "Cell \u001b[0;32mIn[11], line 14\u001b[0m, in \u001b[0;36mload_wesad_dataset\u001b[0;34m(root_dir, test_subject)\u001b[0m\n\u001b[1;32m     12\u001b[0m train_ls \u001b[38;5;241m=\u001b[39m [subject \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m folder_ls \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_ls]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========Loading Training set============\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_process_extract_ls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ls\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWIN_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mWIN_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m==========Loading Testing set============\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/NamQuang/SSLModel/wesad_processing.py:84\u001b[0m, in \u001b[0;36mload_process_extract_ls\u001b[0;34m(root_dir, folder_ls, sample_rate, win_size, strides, is_train)\u001b[0m\n\u001b[1;32m     82\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(file_folder, file)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#Read data and store\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m ecg_temp, label_temp \u001b[38;5;241m=\u001b[39m get_ecg_dataframe(data, sample_rate, win_size, strides,is_train)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/io/pickle.py:210\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlatin-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.10/pickle.py:1338\u001b[0m, in \u001b[0;36m_Unpickler.load_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe STRING opcode argument must be quoted\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_string(\u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mescape_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_ls, f1_score_ls, recall_score_ls, precision_score_ls = loso_training(\"/home/van/NamQuang/Dataset/WESAD_LOSO\", 700,1,'test_loso.csv',  False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2219b-ae89-4086-b5dc-8070c25344c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
